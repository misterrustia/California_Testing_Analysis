{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ab6017-35d6-4e8d-b158-b6675e32ef9c",
   "metadata": {},
   "source": [
    "# objectives - get basic model tested after variance inflation factor used for feature selection\n",
    "\n",
    "- check feature importance afterwards, \n",
    "\n",
    "- set up for advanced model tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258e5235-c291-475d-87e0-7266376e9402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082e5d8b-889a-4862-a71e-54e15a943198",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_model_version = '1.0'\n",
    "model_path = 'models/11th_grade_scoring_model.pkl'\n",
    "if os.path.exists(model_path):\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    if model.version != expected_model_version:\n",
    "        print(\"Expected model version doesn't match version loaded\")\n",
    "    if model.sklearn_version != sklearn_version:\n",
    "        print(\"Warning: model created under different sklearn version\")\n",
    "else:\n",
    "    print(\"Expected model not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23b3d8e-d741-42d1-b89f-c15c885d5894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628893b-218d-4ecb-b1fd-0fa3362fbe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/model/final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d20705-2dc8-42d3-89ae-4122c412a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mills = data[data.school_name == 'Mills High School']\n",
    "\n",
    "capuchino = data[data['School Name'] == 'Cap ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4793d24-349a-4f19-9a3f-eb14526572e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ba364-d186-4b2d-a9b6-056415d7ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_change( model, school,features, deltas):\n",
    "    \n",
    "    adj_school = school.copy()\n",
    "    for f,d in zip(features, deltas):\n",
    "        adj_school[f] += d\n",
    "    return model.predict(adj_school).item() - model.predict(school).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec32acc-777c-4b10-ab86-5ad3f1ee030c",
   "metadata": {},
   "source": [
    "## refit model with all data \n",
    "\n",
    "\n",
    "plot compare key features to be adjusted \n",
    "\n",
    "use predict increase to generate alternative scores due to change in model features \n",
    "\n",
    "graph changes in scores due to adjusted features \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
